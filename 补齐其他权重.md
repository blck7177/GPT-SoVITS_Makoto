# 1) 目录与依赖
cd /workspace/GPT-SoVITS_Makoto || cd /workspace/GPT-SoVITS
python3 -m venv .venv && source .venv/bin/activate
pip -q install -U pip huggingface_hub

# 2) 创建目标目录
mkdir -p GPT_SoVITS/pretrained_models \
         GPT_SoVITS/pretrained_models/v2Pro \
         GPT_SoVITS/pretrained_models/sv \
         GPT_SoVITS/text

# 3) 下载中文前端（RoBERTa & HuBERT）到 pretrained_models/
python - <<'PY'
import os, shutil
from huggingface_hub import hf_hub_download
dst = "GPT_SoVITS/pretrained_models"
for repo, folder in [("lj1995/GPT-SoVITS","chinese-roberta-wwm-ext-large"),
                     ("lj1995/GPT-SoVITS","chinese-hubert-base")]:
    # 拉整目录（用 hf_hub_download 把关键大文件拉到对应子目录）
    os.makedirs(f"{dst}/{folder}", exist_ok=True)
    # 取最核心的模型文件，目录其它文件会在首次加载时再补
    for fname in ["pytorch_model.bin","config.json","tokenizer.json","vocab.txt","spm.model"]:
        try:
            p = hf_hub_download(repo_id=repo, filename=f"{folder}/{fname}")
            shutil.copy(p, f"{dst}/{folder}/{fname}")
        except Exception:
            pass
PY

# 4) 下载并安置 G2PWModel（中文必备）
# 官方 README 指向“G2PWModel.zip(HF/ModelScope)”；这里先尝试常见镜像，再留出自备文件的兜底路径。
python - <<'PY'
import os, zipfile, io
from huggingface_hub import hf_hub_download
os.makedirs("GPT_SoVITS/text", exist_ok=True)
ok=False
for repo in ["XXXXRT/GPT-SoVITS-Pretrained", "kevinwang676/GPT-SoVITS-v-3"]:
    try:
        z = hf_hub_download(repo_id=repo, filename="G2PWModel.zip")
        with zipfile.ZipFile(z) as zz:
            zz.extractall("GPT_SoVITS/text")
        # 解压后目录可能不是G2PWModel，统一改名
        for d in os.listdir("GPT_SoVITS/text"):
            if d.lower().startswith("g2pwmodel"):
                os.rename(f"GPT_SoVITS/text/{d}", "GPT_SoVITS/text/G2PWModel")
                break
        ok=True; break
    except Exception: pass
print("G2PWModel_ok=", ok)
PY
# 如果上面 G2PWModel_ok=False，可以手动把 G2PWModel.zip 放到 /workspace 后：
# unzip /workspace/G2PWModel.zip -d GPT_SoVITS/text && mv GPT_SoVITS/text/*G2PW* GPT_SoVITS/text/G2PWModel

# 5) （可选）SV 验证模型
python - <<'PY'
import os, shutil
from huggingface_hub import hf_hub_download
os.makedirs("GPT_SoVITS/pretrained_models/sv", exist_ok=True)
try:
    p = hf_hub_download("lj1995/GPT-SoVITS", "sv/pretrained_eres2netv2w24s4ep4.ckpt")
    shutil.copy(p, "GPT_SoVITS/pretrained_models/sv/pretrained_eres2netv2w24s4ep4.ckpt")
except Exception: pass
PY

# 6) 写入/覆盖 tts_infer.yaml 的 custom 段，指向你的自训权重与中文前端
cat > GPT_SoVITS/configs/tts_infer.yaml <<'YAML'
custom:
  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large
  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base
  device: cuda
  is_half: true
  # 你的 s1 / s2 权重（保持你现在的路径即可）
  t2s_weights_path: /workspace/weights/makoto_test1-e25.ckpt
  vits_weights_path: /workspace/weights/makoto_test1_e25_s750.pth
  version: v2ProPlus
YAML

# 7) 启动 API
python api_v2.py -a 0.0.0.0 -p 9880 -c GPT_SoVITS/configs/tts_infer.yaml


## 拉取完整目录
# 1) 把中文前端两个目录完整拉下到临时目录
python - <<'PY'
import os, shutil
from huggingface_hub import snapshot_download

tmpdir = snapshot_download(
    repo_id="lj1995/GPT-SoVITS",
    allow_patterns=[
        "chinese-hubert-base/*",
        "chinese-roberta-wwm-ext-large/*",
    ],
)

# 目标目录
dst_root = "GPT_SoVITS/pretrained_models"
os.makedirs(dst_root, exist_ok=True)

for name in ["chinese-hubert-base", "chinese-roberta-wwm-ext-large"]:
    src = os.path.join(tmpdir, name)
    dst = os.path.join(dst_root, name)
    if os.path.exists(dst):
        shutil.rmtree(dst)
    shutil.copytree(src, dst)
print("✅ Copied full frontend folders into", dst_root)
PY

## 补充
对，这个错误是因为我们去 lj1995/GPT-SoVITS 仓库里找 G2PWModel，但官方并没有把它放在那个 repo 里；正确做法是从 PaddleSpeech 的 CDN 或官方镜像（HF / ModelScope）下载 G2PWModel.zip，解压成 GPT_SoVITS/text/G2PWModel/。官方 README / issue 里也这么写的。
GitHub
+1

下面给你一段“三镜像兜底”脚本：优先下 Paddle CDN，失败再试 HF 镜像、ModelScope。直接整段粘贴到 Pod 里执行即可。

set -euo pipefail
cd /workspace/GPT-SoVITS_Makoto
mkdir -p GPT_SoVITS/text
DST="GPT_SoVITS/text/G2PWModel"
rm -rf "$DST" /tmp/G2PWModel /tmp/G2PWModel.zip

# 三个可用源（二选一成功即可）
URLS=(
  "https://paddlespeech.cdn.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip"
  "https://huggingface.co/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/G2PWModel.zip"
  "https://www.modelscope.cn/models/XXXXRT/GPT-SoVITS-Pretrained/resolve/master/G2PWModel.zip"
)

ok=0
for u in "${URLS[@]}"; do
  echo "Trying: $u"
  if curl -L --fail -o /tmp/G2PWModel.zip "$u"; then
    mkdir -p /tmp/G2PWModel && unzip -q /tmp/G2PWModel.zip -d /tmp/G2PWModel
    # 找到包含 g2pW.onnx 的那个目录
    F=$(find /tmp/G2PWModel -type f -name "g2pW.onnx" -printf '%h\n' | head -n1 || true)
    if [ -n "${F:-}" ]; then
      mv "$F" "$DST"
      ok=1
      break
    fi
  fi
done

if [ "$ok" -ne 1 ]; then
  echo "❌ 所有镜像都没下到 G2PWModel，请检查网络或稍后再试"
  exit 1
fi

echo "✅ G2PWModel 就位：$DST"
ls -lh "$DST"


## 安装解压
apt-get update && apt-get install -y unzip

cd /workspace/GPT-SoVITS_Makoto
DST="GPT_SoVITS/text/G2PWModel"

mkdir -p /tmp/G2PWModel
unzip -q /tmp/G2PWModel.zip -d /tmp/G2PWModel

# 找到包含 g2pW.onnx 的真实目录（不同压缩包外层目录名可能不一样）
F=$(dirname "$(find /tmp/G2PWModel -type f -name 'g2pW.onnx' | head -n1)")
[ -n "$F" ] || { echo "❌ 在压缩包里没找到 g2pW.onnx"; exit 1; }

# 覆盖到项目要求的位置：GPT_SoVITS/text/G2PWModel
rm -rf "$DST"
mkdir -p "$(dirname "$DST")"
mv "$F" "$DST"

# 快速校验
ls -lh "$DST/g2pW.onnx"

## 补齐英语模块
python - << 'PY'
import nltk
# NLTK 3.8+ 用 *_eng；老版本用不带 _eng 的名字，两个都下最稳
for pkg in ['averaged_perceptron_tagger_eng', 'averaged_perceptron_tagger',
            'cmudict', 'punkt']:
    try:
        nltk.download(pkg)
    except Exception as e:
        print('download failed:', pkg, e)
PY


# URL

## 启动
bash scripts/start.sh